{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "import seaborn as sb\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\r\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = pd.read_csv(\"Data/dataset.csv\")\r\n",
    "data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data['Disorder'].unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Converting the dataset to a numpy array"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = np.array(data.to_numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Labeling the categorical data using label encoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "le=LabelEncoder()\r\n",
    "for i in data[:]:\r\n",
    "    data[i]=le.fit(data[i]).transform(data[i])\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading the Column names"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "col = list()\r\n",
    "for i in data:\r\n",
    "    col.append(i)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checking for null values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting data into variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X,Y=data[col[:24]], data['Disorder']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting into training and testing data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, Y_train, y_test=train_test_split(X,Y, test_size=.33, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision tree classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "clf_gini = DecisionTreeClassifier(  max_depth= 10,\r\n",
    "                                    max_features = 'auto',\r\n",
    "                                    min_samples_leaf= 1,\r\n",
    "                                    min_samples_split = 2)\r\n",
    "clf_gini.fit(X_train, Y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred_gini = clf_gini.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import accuracy_score\r\n",
    "print('Model accuracy score with criterion gini index: {0:0.4f}'. format(accuracy_score(y_test, y_pred_gini)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prediction_test = clf_gini.predict(X_test)\r\n",
    "classes = ['Anxiety', 'Depression', 'Loneliness', 'Stress', 'Normal']\r\n",
    "def plot_confusionmatrix(pred,test,dom):\r\n",
    "    print(f'{dom} Confusion matrix')\r\n",
    "    cf = confusion_matrix(pred,test)\r\n",
    "    sb.heatmap(cf,annot=True,yticklabels=classes\r\n",
    "               ,xticklabels=classes,cmap='Blues', fmt='g')\r\n",
    "    plt.tight_layout()\r\n",
    "    plt.show()    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Training Accuracy\r\n",
    "print(\"Training Accuracy is: \", clf_gini.score(X_train, Y_train))\r\n",
    "#Test Accuracy\r\n",
    "print(\"Testing Accuracy is: \", clf_gini.score(X_test, y_test))\r\n",
    "\r\n",
    "\r\n",
    "plot_confusionmatrix(y_test,prediction_test,dom='Test')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "model = RandomForestClassifier(bootstrap= True,\r\n",
    " max_depth = 1,\r\n",
    " max_features = 'auto',\r\n",
    " min_samples_leaf = 1,\r\n",
    " min_samples_split = 2,\r\n",
    " n_estimators = 20)\r\n",
    "model.fit(X_train, Y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "random_predict = model.predict(X_test)\r\n",
    "print('Model accuracy score with criterion gini index: {0:0.4f}'. format(accuracy_score(y_test, random_predict)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Training Accuracy\r\n",
    "print(\"Training Accuracy is: \", model.score(X_train, Y_train))\r\n",
    "#Test Accuracy\r\n",
    "print(\"Testing Accuracy is: \", model.score(X_test, y_test))\r\n",
    "\r\n",
    "\r\n",
    "plot_confusionmatrix(y_test,prediction_test,dom='Test')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Case 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t1 = ['panic' , 'trouble.in.concentration', 'having.trouble.in.sleeping', 'feeling.nervous' , 'sweating']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "r = []\r\n",
    "for i in col[0:24]:\r\n",
    "    if i in t1:\r\n",
    "        r.append(1)\r\n",
    "    else:\r\n",
    "        r.append(0)\r\n",
    "b=[r]\r\n",
    "test = pd.DataFrame(b)\r\n",
    "test\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if y_pred_gini[0] == 0:\r\n",
    "    disorder = \"Anxiety\"\r\n",
    "elif y_pred_gini[0] == 1:\r\n",
    "    disorder = \"Depression\"\r\n",
    "elif y_pred_gini[0] == 2:\r\n",
    "    disorder = \"Loneliness\"\r\n",
    "elif y_pred_gini[0] == 3:\r\n",
    "    disorder = \"Normal\"\r\n",
    "elif y_pred_gini[0] == 4:\r\n",
    "    disorder = \"Stress\"\r\n",
    "\r\n",
    "print(disorder)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyper parameter Tuning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X,Y=data[col[:24]], data['Disorder']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Number of trees in random forest\r\n",
    "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 100, num = 10)]\r\n",
    "# Number of features to consider at every split\r\n",
    "max_features = ['auto', 'sqrt']\r\n",
    "# Maximum number of levels in tree\r\n",
    "max_depth = [10,20]\r\n",
    "# Minimum number of samples required to split a node\r\n",
    "min_samples_split = [2, 5]\r\n",
    "# Minimum number of samples required at each leaf node\r\n",
    "min_samples_leaf = [1, 2]\r\n",
    "# Method of selecting samples for training each tree\r\n",
    "bootstrap = [True, False]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the param grid\r\n",
    "import random\r\n",
    "param_grid = {'n_estimators': n_estimators,\r\n",
    "               'max_features': max_features,\r\n",
    "               'max_depth': max_depth,\r\n",
    "               'min_samples_split': min_samples_split,\r\n",
    "               'min_samples_leaf': min_samples_leaf,\r\n",
    "               'bootstrap': bootstrap}\r\n",
    "print(param_grid)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = RandomForestClassifier()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV\r\n",
    "rf_Grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = 20, verbose=2, n_jobs = 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rf_Grid.fit(X_train, Y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rf_Grid.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print (f'Train Accuracy - : {rf_Grid.score(X_train,Y_train):.3f}')\r\n",
    "print (f'Test Accuracy - : {rf_Grid.score(X_test,y_test):.3f}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prediction_test = rf_Grid.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_confusionmatrix(y_test,prediction_test,dom='Test')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('penv': venv)"
  },
  "interpreter": {
   "hash": "ee25deaa157146aa5ab983906bb6a065bee9b1c63fc59cc7edac0e5187fae9dd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}